eval_interval: 250 # keep frequent because we'll overfit
eval_iters: 25
eval_only: false
init_from: scratch
seed: 42
gradient_accumulation_steps: 1
batch_size: 128
device: cuda

data_fraction: 1.0
train_data:
  data_dir: ukb_real_data
  memmap_fname: train.bin
  seed: 42
  biomarker_dir: ukb_real_data/biomarkers
  biomarkers:
    prs: ${model.biomarkers.prs.n_token}
    family_hx: ${model.biomarkers.family_hx.n_token}
    # blood_all: ${model.biomarkers.blood_all.n_token}
    wbc: ${model.biomarkers.wbc.n_token}
    lipid: ${model.biomarkers.lipid.n_token}
    lft: ${model.biomarkers.lft.n_token}
    renal: ${model.biomarkers.renal.n_token}
    hba1c: ${model.biomarkers.hba1c.n_token}
    crp: ${model.biomarkers.crp.n_token}
    urate: ${model.biomarkers.urate.n_token}
    cysc: ${model.biomarkers.cysc.n_token}
    apo: ${model.biomarkers.apo.n_token}
    vitd: ${model.biomarkers.vitd.n_token}
    dht: ${model.biomarkers.dht.n_token}
    shbg: ${model.biomarkers.shbg.n_token}
    igf1: ${model.biomarkers.igf1.n_token}
  transforms:
    - name: no-event
      args:
        interval_in_years: 5
        mode: random
val_data:
  data_dir: ukb_real_data
  memmap_fname: val.bin
  seed: 42
  biomarker_dir: ukb_real_data/biomarkers
  biomarkers:
    prs: ${model.biomarkers.prs.n_token}
    family_hx: ${model.biomarkers.family_hx.n_token}
    # blood_all: ${model.biomarkers.blood_all.n_token}
    wbc: ${model.biomarkers.wbc.n_token}
    lipid: ${model.biomarkers.lipid.n_token}
    lft: ${model.biomarkers.lft.n_token}
    renal: ${model.biomarkers.renal.n_token}
    hba1c: ${model.biomarkers.hba1c.n_token}
    crp: ${model.biomarkers.crp.n_token}
    urate: ${model.biomarkers.urate.n_token}
    cysc: ${model.biomarkers.cysc.n_token}
    apo: ${model.biomarkers.apo.n_token}
    vitd: ${model.biomarkers.vitd.n_token}
    dht: ${model.biomarkers.dht.n_token}
    shbg: ${model.biomarkers.shbg.n_token}
    igf1: ${model.biomarkers.igf1.n_token}
  transforms:
    - name: no-event
      args:
        interval_in_years: 5
        mode: random
model:
  block_size: 48
  vocab_size: 1271
  n_layer: 12
  n_head: 12
  n_embd: 120
  dropout: 0.1
  token_dropout: 0.0
  t_min: 0.1
  bias: true
  mask_ties: true
  ignore_tokens:
    - padding
    - male
    - female
    - config/disease_list/lifestyle.yaml
  biomarkers:
    prs:
      projector: linear
      input_size: 36
      n_token: 1
    family_hx:
      projector: embed
      vocab_size: 15
      n_token: null
    # blood_all:
    #   projector: linear
    #   input_size: 57
    #   n_token: 1
    wbc:
      projector: linear
      input_size: 31
      n_token: 1
    lipid:
      projector: linear
      input_size: 4
      n_token: 1
    lft:
      projector: linear
      input_size: 7
      n_token: 1
    renal:
      projector: linear
      input_size: 6
      n_token: 1
    hba1c:
      projector: linear
      input_size: 1
      n_token: 1
    crp:
      projector: linear
      input_size: 1
      n_token: 1
    urate:
      projector: linear
      input_size: 1
      n_token: 1
    cysc:
      projector: linear
      input_size: 1
      n_token: 1
    apo:
      projector: linear
      input_size: 2
      n_token: 1
    vitd:
      projector: linear
      input_size: 1
      n_token: 1
    dht:
      projector: linear
      input_size: 1
      n_token: 1
    shbg:
      projector: linear
      input_size: 1
      n_token: 1
    igf1:
      projector: linear
      input_size: 1
      n_token: 1
  modality_emb: true
  loss:
    ce_beta: 1.0
    dt_beta: 1.0
    zero_inflate: false
log:
  wandb_log: true
  wandb_project: delphi
  log_interval: 25
  always_ckpt_after_eval: true
  ckpt_interval: null
optim:
  learning_rate: 6e-4 # with baby networks can afford to go a bit higher
  max_iters: 100000
  weight_decay: 2e-1
  lr_decay_iters: 100000 # make equal to max_iters usually
  min_lr: 6e-5 # learning_rate / 10 usually
  beta2: 0.99 # make a bit bigger because number of tokens per iter is small
  warmup_iters: 1000 # not super necessary potentially
