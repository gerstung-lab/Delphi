model_type: ethos
ckpt_dir: ethos-mimic
eval_interval: 1000
eval_iters: 25
eval_only: false
init_from: scratch
seed: 42
gradient_accumulation_steps: 1
batch_size: 256
device: cuda
data:
  data_dir: mimic
  seed: 42
  block_size: ${model.block_size}
model:
  vocab_size: 4544
  n_layer: 10
  n_head: 8
  n_embd: 256
  embd_pdrop: 0.3
  bias: true
  block_size: 1024
log:
  wandb_log: true
  wandb_project: ${ckpt_dir}
  run_name: ethos-mimic-50k
  log_interval: 250
  always_ckpt_after_eval: true
  ckpt_interval: null
optim:
  learning_rate: 6e-4
  max_iters: 50000
  weight_decay: 2e-1
  lr_decay_iters: ${optim.max_iters}
  min_lr: 6e-5
  beta2: 0.99
  warmup_iters: 500
