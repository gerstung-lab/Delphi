model_type: ethos
ckpt_dir: ethos
eval_interval: 500
eval_iters: 25
eval_only: false
init_from: scratch
seed: 42
gradient_accumulation_steps: 1
batch_size: 256
device: cuda
data:
  data_dir: ukb_real_data
  train_subject_list: participants/train_fold.bin
  val_subject_list: participants/val_fold.bin
  seed: 42
  block_size: ${model.block_size}
  no_event_interval: 5
model:
  base_vocab_size: 1270
  vocab_size: 1370
  n_layer: 12
  n_head: 12
  n_embd: 120
  dropout: 0.1
  token_dropout: 0.0
  bias: true
  block_size: 512
  n_time_tokens: 100
  time_bins: []
log:
  wandb_log: true
  wandb_project: ${ckpt_dir}
  run_name: ${model.n_time_tokens}_time_tokens
  log_interval: 25
  always_ckpt_after_eval: true
  ckpt_interval: null
optim:
  learning_rate: 6e-4
  max_iters: 50000
  weight_decay: 2e-1
  lr_decay_iters: ${optim.max_iters}
  min_lr: 6e-5
  beta2: 0.99
  warmup_iters: 1000
